{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a20c9fd-1be2-4fe5-b1cf-757a0d6939d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom CSS styling\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".widget-label { font-weight: bold; font-size: 14px; }\n",
    ".success-box { background-color: #d4edda; border: 2px solid #28a745; \n",
    "               border-radius: 10px; padding: 15px; margin: 10px 0; }\n",
    ".warning-box { background-color: #fff3cd; border: 2px solid #ffc107; \n",
    "               border-radius: 10px; padding: 15px; margin: 10px 0; }\n",
    ".danger-box { background-color: #f8d7da; border: 2px solid #dc3545; \n",
    "              border-radius: 10px; padding: 15px; margin: 10px 0; }\n",
    ".info-box { background-color: #d1ecf1; border: 2px solid #17a2b8; \n",
    "            border-radius: 10px; padding: 15px; margin: 10px 0; }\n",
    ".segment-box { background-color: #f8f9fa; border: 1px solid #dee2e6; \n",
    "               border-radius: 8px; padding: 12px; margin: 8px 0; }\n",
    ".help-text { color: #666; font-size: 13px; margin-top: 5px; margin-bottom: 15px; \n",
    "             padding: 10px; background-color: #f8f9fa; border-left: 3px solid #17a2b8; \n",
    "             border-radius: 4px; line-height: 1.5; }\n",
    ".example-text { color: #28a745; font-weight: bold; }\n",
    ".section-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                  color: white; padding: 15px; border-radius: 10px; margin: 20px 0 10px 0; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "# Title\n",
    "display(HTML(\"\"\"\n",
    "<h1>\uD83D\uDCCA A/B Test Calculator with Segmentation</h1>\n",
    "<p style='font-size: 16px; color: #666;'>Analyze overall results and segment-level performance</p>\n",
    "<div class='info-box'>\n",
    "    <strong>What is A/B Testing?</strong><br>\n",
    "    A/B testing compares two versions (A and B) to see which performs better. Version A is the \"Control\" \n",
    "    (what you have now), and Version B is the \"Treatment\" (the new version you're testing).\n",
    "    This calculator tells you if the difference between them is real or just random chance.\n",
    "</div>\n",
    "<hr>\n",
    "\"\"\"))\n",
    "\n",
    "# Create output area for results\n",
    "output = widgets.Output()\n",
    "\n",
    "# Input widgets with enhanced descriptions\n",
    "ci_selector = widgets.Dropdown(\n",
    "    options=[('90% (Less Strict)', 90), ('95% (Standard)', 95), ('99% (Very Strict)', 99)],\n",
    "    value=95,\n",
    "    description='Confidence Level:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"<div class='section-header'><h3 style='margin:0;'>⚙️ Test Configuration</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Confidence Level</strong><br>\n",
    "    This is how sure you want to be that your results are real, not just luck.<br>\n",
    "    • <span class='example-text'>95% (Standard)</span> - Industry standard. Means there's only a 5% chance your results are due to random chance.<br>\n",
    "    • <span class='example-text'>99% (Very Strict)</span> - Use when decisions have high stakes or costs.<br>\n",
    "    • <span class='example-text'>90% (Less Strict)</span> - Use for quick tests or low-risk decisions.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(ci_selector)\n",
    "\n",
    "# Enable segmentation toggle\n",
    "enable_segmentation = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Enable Segment Analysis (Advanced)',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Test duration inputs\n",
    "test_duration_days = widgets.IntText(\n",
    "    value=14,\n",
    "    description='Test Duration (days):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "average_session_days = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description='Avg Days Between Sessions:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"<br><div class='section-header'><h3 style='margin:0;'>⏱️ Test Duration</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC How Long Did Your Test Run?</strong><br>\n",
    "    Enter the number of days your test was live. Longer tests = more reliable results.<br>\n",
    "    <span class='example-text'>Recommendation:</span> Run for at least 14 days (2 full weeks) to capture weekly patterns \n",
    "    (e.g., weekday vs. weekend behavior).<br>\n",
    "    <span class='example-text'>Example:</span> If you started the test on Monday and ended it two weeks later on Sunday, enter 14.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(test_duration_days)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC How Often Do Users Return?</strong><br>\n",
    "    On average, how many days pass before the same user comes back to your site/app?<br>\n",
    "    • <span class='example-text'>1.0</span> - Users visit daily (e.g., social media, news sites)<br>\n",
    "    • <span class='example-text'>3.5</span> - Users visit a few times per week (e.g., shopping sites)<br>\n",
    "    • <span class='example-text'>7.0</span> - Users visit weekly (e.g., meal planning apps)<br>\n",
    "    • <span class='example-text'>30.0</span> - Users visit monthly (e.g., utility bill payments)<br>\n",
    "    <br>\n",
    "    <strong>Why this matters:</strong> If users return frequently during the test, the same person might see both \n",
    "    versions, which can skew results. The calculator will warn you if this is a problem.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(average_session_days)\n",
    "\n",
    "# Randomization quality inputs\n",
    "expected_split = widgets.FloatText(\n",
    "    value=0.50,\n",
    "    description='Expected Traffic Split:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "user_overlap_pct = widgets.FloatText(\n",
    "    value=0.0,\n",
    "    description='Est. User Overlap (%):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"<br><div class='section-header'><h3 style='margin:0;'>\uD83C\uDFB2 Randomization Quality Check</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Expected Traffic Split</strong><br>\n",
    "    What percentage of users did you <strong>intend</strong> to send to the Control group?<br>\n",
    "    • <span class='example-text'>0.50</span> - 50/50 split (most common - half see Control, half see Treatment)<br>\n",
    "    • <span class='example-text'>0.70</span> - 70/30 split (70% see Control, 30% see Treatment - use when you want to limit exposure to the new version)<br>\n",
    "    • <span class='example-text'>0.90</span> - 90/10 split (risky changes - test with only 10% of users first)<br>\n",
    "    <br>\n",
    "    <strong>Why this matters:</strong> The calculator checks if your actual split matches what you intended. \n",
    "    A big mismatch suggests a technical problem with your test setup.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(expected_split)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC User Overlap Percentage</strong><br>\n",
    "    What percentage of users saw <strong>BOTH</strong> the Control and Treatment during the test?<br>\n",
    "    • <span class='example-text'>0%</span> - Perfect! Each user only saw one version (ideal)<br>\n",
    "    • <span class='example-text'>1-5%</span> - Acceptable. Small overlap won't significantly affect results<br>\n",
    "    • <span class='example-text'>5-10%</span> - Concerning. Results might be biased<br>\n",
    "    • <span class='example-text'>10%+</span> - Major problem. Users seeing both versions can contaminate results<br>\n",
    "    <br>\n",
    "    <strong>How to estimate:</strong> Check your analytics for users with multiple sessions who saw different versions. \n",
    "    If you're not sure, start with 0% and the calculator will help you assess risk.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(user_overlap_pct)\n",
    "\n",
    "# Segment input area (initially hidden)\n",
    "segment_input_area = widgets.VBox([])\n",
    "\n",
    "# Number of segments selector\n",
    "num_segments = widgets.Dropdown(\n",
    "    options=[2, 3, 4, 5],\n",
    "    value=2,\n",
    "    description='Number of Segments:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"<br><div class='section-header'><h3 style='margin:0;'>\uD83D\uDCCA Segment Analysis (Optional)</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC What Are Segments?</strong><br>\n",
    "    Segments let you see if your test worked differently for different groups of users.<br>\n",
    "    <span class='example-text'>Examples:</span><br>\n",
    "    • Mobile vs. Desktop users<br>\n",
    "    • New vs. Returning customers<br>\n",
    "    • Geographic regions (US vs. Europe vs. Asia)<br>\n",
    "    • Age groups or subscription tiers<br>\n",
    "    <br>\n",
    "    <strong>When to use:</strong> Enable this if you want to check whether the treatment works better for \n",
    "    some types of users than others. Leave it off for simpler analysis.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(enable_segmentation)\n",
    "display(segment_input_area)\n",
    "\n",
    "# Overall data inputs\n",
    "display(HTML(\"<br><div class='section-header'><h3 style='margin:0;'>\uD83D\uDCC8 Overall Test Data</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Enter Your Test Results</strong><br>\n",
    "    Fill in the numbers from your experiment. Don't worry - there are detailed explanations below each field!\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "control_visitors = widgets.IntText(\n",
    "    value=10000,\n",
    "    description='Control Visitors:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "control_conversions = widgets.IntText(\n",
    "    value=1200,\n",
    "    description='Control Conversions:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "treatment_visitors = widgets.IntText(\n",
    "    value=10000,\n",
    "    description='Treatment Visitors:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "treatment_conversions = widgets.IntText(\n",
    "    value=1350,\n",
    "    description='Treatment Conversions:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Control Visitors (Version A)</strong><br>\n",
    "    How many people saw the <strong>original</strong> version (the Control)?<br>\n",
    "    <span class='example-text'>Example:</span> If 10,000 people saw your current website design, enter 10000.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(control_visitors)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Control Conversions</strong><br>\n",
    "    Out of the Control visitors, how many completed your desired action?<br>\n",
    "    <span class='example-text'>Example actions:</span> Made a purchase, signed up, clicked a button, downloaded a file.<br>\n",
    "    <span class='example-text'>Example:</span> If 1,200 of those 10,000 visitors made a purchase, enter 1200.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(control_conversions)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Treatment Visitors (Version B)</strong><br>\n",
    "    How many people saw the <strong>new</strong> version (the Treatment)?<br>\n",
    "    <span class='example-text'>Example:</span> If 10,000 people saw your new website design, enter 10000.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(treatment_visitors)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Treatment Conversions</strong><br>\n",
    "    Out of the Treatment visitors, how many completed your desired action?<br>\n",
    "    <span class='example-text'>Example:</span> If 1,350 of those 10,000 visitors made a purchase, enter 1350.<br>\n",
    "    <br>\n",
    "    <strong>Quick Check:</strong> In this example, Control had 12% conversion (1200/10000) and Treatment had 13.5% \n",
    "    (1350/10000), suggesting the new version might be better.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(treatment_conversions)\n",
    "\n",
    "current_revenue = widgets.FloatText(\n",
    "    value=100000.0,\n",
    "    description='Monthly Revenue ($):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "seasonal_multiplier = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description='Seasonal Multiplier:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "display(HTML(\"<br><div class='section-header'><h3 style='margin:0;'>\uD83D\uDCB0 Revenue Impact (Optional)</h3></div>\"))\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Monthly Revenue</strong><br>\n",
    "    What's your current monthly revenue from the area you're testing?<br>\n",
    "    <span class='example-text'>Example:</span> If your e-commerce site makes $100,000/month, enter 100000.<br>\n",
    "    <br>\n",
    "    <strong>Why this matters:</strong> The calculator will estimate how much additional annual revenue \n",
    "    you could generate if you roll out the winning version to everyone.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(current_revenue)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div class='help-text'>\n",
    "    <strong>\uD83D\uDCCC Seasonal Multiplier</strong><br>\n",
    "    Will the season affect the revenue impact?<br>\n",
    "    • <span class='example-text'>1.0</span> - Normal/average season (use this if unsure)<br>\n",
    "    • <span class='example-text'>1.5</span> - Peak season (e.g., holiday shopping - revenue is 50% higher than normal)<br>\n",
    "    • <span class='example-text'>0.7</span> - Slow season (e.g., January after holidays - revenue is 30% lower)<br>\n",
    "    <br>\n",
    "    <strong>Example:</strong> If you're testing during Black Friday when revenue is typically 2x normal, \n",
    "    enter 2.0 to get more accurate annual projections.\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(seasonal_multiplier)\n",
    "\n",
    "# Storage for segment widgets\n",
    "segment_widgets = {}\n",
    "\n",
    "def create_segment_inputs(n):\n",
    "    \"\"\"Create input fields for n segments\"\"\"\n",
    "    segment_boxes = []\n",
    "    segment_widgets.clear()\n",
    "    \n",
    "    display(HTML(\"\"\"\n",
    "    <div class='help-text'>\n",
    "        <strong>\uD83D\uDCCC How to Fill in Segment Data</strong><br>\n",
    "        For each segment, enter the visitors and conversions separately for Control and Treatment.<br>\n",
    "        <span class='example-text'>Example Segments:</span><br>\n",
    "        • <strong>Mobile Users:</strong> Control: 6,000 visitors, 600 conversions | Treatment: 6,100 visitors, 700 conversions<br>\n",
    "        • <strong>Desktop Users:</strong> Control: 4,000 visitors, 600 conversions | Treatment: 3,900 visitors, 650 conversions<br>\n",
    "        <br>\n",
    "        <strong>Tip:</strong> Make sure the sum of all segments roughly equals your overall numbers above!\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    for i in range(n):\n",
    "        segment_name = widgets.Text(\n",
    "            value=f'Segment {i+1}',\n",
    "            description=f'Segment {i+1} Name:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        ctrl_v = widgets.IntText(\n",
    "            value=int(10000/n),\n",
    "            description='Control Visitors:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        ctrl_c = widgets.IntText(\n",
    "            value=int(1200/n),\n",
    "            description='Control Conversions:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        treat_v = widgets.IntText(\n",
    "            value=int(10000/n),\n",
    "            description='Treatment Visitors:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        treat_c = widgets.IntText(\n",
    "            value=int(1350/n),\n",
    "            description='Treatment Conversions:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        segment_widgets[i] = {\n",
    "            'name': segment_name,\n",
    "            'ctrl_v': ctrl_v,\n",
    "            'ctrl_c': ctrl_c,\n",
    "            'treat_v': treat_v,\n",
    "            'treat_c': treat_c\n",
    "        }\n",
    "        \n",
    "        box = widgets.VBox([\n",
    "            widgets.HTML(f\"<div class='segment-box'><h4>Segment {i+1}</h4><p style='color:#666;font-size:12px;'>Give this segment a descriptive name (e.g., 'Mobile Users', 'New Customers')</p></div>\"),\n",
    "            segment_name,\n",
    "            widgets.HTML(\"<p style='color:#666;font-size:12px;margin-left:10px;'>Number of users in this segment who saw the Control version:</p>\"),\n",
    "            ctrl_v,\n",
    "            widgets.HTML(\"<p style='color:#666;font-size:12px;margin-left:10px;'>Number of Control users who converted:</p>\"),\n",
    "            ctrl_c,\n",
    "            widgets.HTML(\"<p style='color:#666;font-size:12px;margin-left:10px;'>Number of users in this segment who saw the Treatment version:</p>\"),\n",
    "            treat_v,\n",
    "            widgets.HTML(\"<p style='color:#666;font-size:12px;margin-left:10px;'>Number of Treatment users who converted:</p>\"),\n",
    "            treat_c,\n",
    "            widgets.HTML(\"<br>\")\n",
    "        ])\n",
    "        segment_boxes.append(box)\n",
    "    \n",
    "    return widgets.VBox(segment_boxes)\n",
    "\n",
    "def on_segmentation_change(change):\n",
    "    \"\"\"Handle segmentation toggle\"\"\"\n",
    "    if change['new']:\n",
    "        segment_input_area.children = [\n",
    "            widgets.HTML(\"<h3>\uD83D\uDCCA Segment Data</h3>\"),\n",
    "            num_segments,\n",
    "            create_segment_inputs(num_segments.value)\n",
    "        ]\n",
    "    else:\n",
    "        segment_input_area.children = []\n",
    "\n",
    "def on_num_segments_change(change):\n",
    "    \"\"\"Handle change in number of segments\"\"\"\n",
    "    if enable_segmentation.value:\n",
    "        segment_input_area.children = [\n",
    "            widgets.HTML(\"<h3>\uD83D\uDCCA Segment Data</h3>\"),\n",
    "            num_segments,\n",
    "            create_segment_inputs(change['new'])\n",
    "        ]\n",
    "\n",
    "enable_segmentation.observe(on_segmentation_change, names='value')\n",
    "num_segments.observe(on_num_segments_change, names='value')\n",
    "\n",
    "# Calculate button\n",
    "calculate_button = widgets.Button(\n",
    "    description='\uD83E\uDDEE Calculate Results',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='400px', height='50px'),\n",
    "    style={'font_weight': 'bold', 'font_size': '16px'}\n",
    ")\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<br>\n",
    "<div class='info-box'>\n",
    "    <strong>✅ Ready to Calculate?</strong><br>\n",
    "    Once you've filled in all the fields above, click the button below to see your results!<br>\n",
    "    The calculator will show you:<br>\n",
    "    • Whether your test results are statistically significant (real or just luck)<br>\n",
    "    • How much improvement the Treatment version provides<br>\n",
    "    • Potential revenue impact<br>\n",
    "    • Quality checks on your test setup<br>\n",
    "    • Visual charts to help you understand the data\n",
    "</div>\n",
    "<br>\n",
    "\"\"\"))\n",
    "\n",
    "display(calculate_button)\n",
    "\n",
    "# Calculation function\n",
    "def calculate_ab_test(ci, ctrl_v, ctrl_c, treat_v, treat_c, revenue, seasonal):\n",
    "    \"\"\"Calculate A/B test results\"\"\"\n",
    "    if ctrl_v == 0 or treat_v == 0:\n",
    "        return None\n",
    "        \n",
    "    control_rate = ctrl_c / ctrl_v\n",
    "    treatment_rate = treat_c / treat_v\n",
    "    \n",
    "    pooled_rate = (ctrl_c + treat_c) / (ctrl_v + treat_v)\n",
    "    se = np.sqrt(pooled_rate * (1 - pooled_rate) * (1/ctrl_v + 1/treat_v))\n",
    "    \n",
    "    lift_abs = treatment_rate - control_rate\n",
    "    lift_rel = (lift_abs / control_rate) * 100 if control_rate > 0 else 0\n",
    "    \n",
    "    z_stat = lift_abs / se if se > 0 else 0\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "    \n",
    "    confidence_level = ci / 100\n",
    "    alpha = 1 - confidence_level\n",
    "    z_critical = stats.norm.ppf(1 - alpha / 2)\n",
    "    \n",
    "    ci_margin = z_critical * se\n",
    "    ci_lower = lift_abs - ci_margin\n",
    "    ci_upper = lift_abs + ci_margin\n",
    "    \n",
    "    is_significant = p_value < alpha\n",
    "    \n",
    "    annual_revenue = revenue * 12\n",
    "    revenue_impact = annual_revenue * lift_abs * seasonal\n",
    "    \n",
    "    mde = 0.02\n",
    "    recommended_n = int(np.ceil(\n",
    "        (2 * (z_critical ** 2) * control_rate * (1 - control_rate)) / (mde ** 2)\n",
    "    )) if control_rate > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'control_rate': control_rate,\n",
    "        'treatment_rate': treatment_rate,\n",
    "        'lift_abs': lift_abs,\n",
    "        'lift_rel': lift_rel,\n",
    "        'z_stat': z_stat,\n",
    "        'p_value': p_value,\n",
    "        'is_significant': is_significant,\n",
    "        'confidence_level': confidence_level,\n",
    "        'alpha': alpha,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'revenue_impact': revenue_impact,\n",
    "        'current_n': ctrl_v,\n",
    "        'recommended_n': recommended_n,\n",
    "        'z_critical': z_critical\n",
    "    }\n",
    "\n",
    "def assess_randomization_quality(ctrl_visitors, treat_visitors, expected_split, user_overlap_pct):\n",
    "    \"\"\"Assess quality of randomization and independence\"\"\"\n",
    "    warnings = []\n",
    "    recommendations = []\n",
    "    validations = []\n",
    "    \n",
    "    total_visitors = ctrl_visitors + treat_visitors\n",
    "    actual_split = ctrl_visitors / total_visitors if total_visitors > 0 else 0\n",
    "    \n",
    "    # Sample Ratio Mismatch (SRM) Check\n",
    "    expected_ctrl = total_visitors * expected_split\n",
    "    expected_treat = total_visitors * (1 - expected_split)\n",
    "    \n",
    "    chi_square_stat = ((ctrl_visitors - expected_ctrl)**2 / expected_ctrl + \n",
    "                       (treat_visitors - expected_treat)**2 / expected_treat)\n",
    "    srm_p_value = 1 - stats.chi2.cdf(chi_square_stat, df=1)\n",
    "    \n",
    "    has_srm = srm_p_value < 0.001\n",
    "    \n",
    "    if has_srm:\n",
    "        warnings.append(f\"\uD83D\uDEA8 CRITICAL: Sample Ratio Mismatch detected (p={srm_p_value:.6f})\")\n",
    "        warnings.append(f\"   Expected: {expected_split*100:.1f}% / {(1-expected_split)*100:.1f}%, Got: {actual_split*100:.2f}% / {(1-actual_split)*100:.2f}%\")\n",
    "        recommendations.append(\"Investigate randomization implementation - this indicates a serious technical issue\")\n",
    "        recommendations.append(\"Common causes: buggy bucketing logic, bot traffic, user switching between groups\")\n",
    "    else:\n",
    "        validations.append(f\"✓ Sample ratio is acceptable ({actual_split*100:.2f}% / {(1-actual_split)*100:.2f}%)\")\n",
    "    \n",
    "    split_deviation = abs(actual_split - expected_split)\n",
    "    if split_deviation > 0.02 and not has_srm:\n",
    "        warnings.append(f\"⚠️ Traffic split deviates by {split_deviation*100:.1f}% from expected\")\n",
    "        recommendations.append(\"Monitor split ratio throughout test duration\")\n",
    "    \n",
    "    if user_overlap_pct > 5:\n",
    "        warnings.append(f\"⚠️ High user overlap ({user_overlap_pct:.1f}%) may violate independence assumption\")\n",
    "        recommendations.append(\"Users seeing both variants can bias results\")\n",
    "        recommendations.append(\"Consider: persistent cookies, account-based bucketing, or user ID tracking\")\n",
    "    elif user_overlap_pct > 0:\n",
    "        validations.append(f\"✓ User overlap is low ({user_overlap_pct:.1f}%)\")\n",
    "    else:\n",
    "        validations.append(\"✓ No user overlap reported\")\n",
    "    \n",
    "    if ctrl_visitors < 100 or treat_visitors < 100:\n",
    "        warnings.append(\"⚠️ Very small sample sizes - balance may be due to chance\")\n",
    "        recommendations.append(\"Continue test to accumulate more data before drawing conclusions\")\n",
    "    \n",
    "    min_detectable_imbalance = 2 * np.sqrt((1 / ctrl_visitors) + (1 / treat_visitors)) * 1.96\n",
    "    \n",
    "    return {\n",
    "        'actual_split': actual_split,\n",
    "        'expected_split': expected_split,\n",
    "        'split_deviation': split_deviation,\n",
    "        'srm_p_value': srm_p_value,\n",
    "        'has_srm': has_srm,\n",
    "        'chi_square_stat': chi_square_stat,\n",
    "        'user_overlap_pct': user_overlap_pct,\n",
    "        'warnings': warnings,\n",
    "        'recommendations': recommendations,\n",
    "        'validations': validations,\n",
    "        'min_detectable_imbalance': min_detectable_imbalance\n",
    "    }\n",
    "\n",
    "def create_randomization_viz(randomization_assessment):\n",
    "    \"\"\"Visualize randomization quality\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    actual = randomization_assessment['actual_split']\n",
    "    expected = randomization_assessment['expected_split']\n",
    "    has_srm = randomization_assessment['has_srm']\n",
    "    srm_p = randomization_assessment['srm_p_value']\n",
    "    \n",
    "    # Chart 1: Traffic Split Comparison\n",
    "    categories = ['Expected', 'Actual']\n",
    "    ctrl_splits = [expected * 100, actual * 100]\n",
    "    treat_splits = [(1-expected) * 100, (1-actual) * 100]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, ctrl_splits, width, label='Control', \n",
    "                    color='#1976d2', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    bars2 = ax1.bar(x + width/2, treat_splits, width, label='Treatment', \n",
    "                    color='#388e3c', alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax1.set_ylabel('Traffic Split (%)', fontweight='bold')\n",
    "    ax1.set_title('Expected vs Actual Traffic Split', fontweight='bold', pad=15)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(categories)\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    ax1.axhline(50, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, height + 0.5,\n",
    "                    f'{height:.2f}%', ha='center', va='bottom', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "    \n",
    "    if has_srm:\n",
    "        ax1.text(0.5, 0.95, '\uD83D\uDEA8 SRM DETECTED', transform=ax1.transAxes,\n",
    "                ha='center', va='top', fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "    else:\n",
    "        ax1.text(0.5, 0.95, '✓ Balance OK', transform=ax1.transAxes,\n",
    "                ha='center', va='top', fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round', facecolor='green', alpha=0.3))\n",
    "    \n",
    "    # Chart 2: SRM Chi-Square Test\n",
    "    chi_stat = randomization_assessment['chi_square_stat']\n",
    "    critical_value = stats.chi2.ppf(0.999, df=1)\n",
    "    \n",
    "    ax2.bar(['Chi-Square\\nStatistic', 'Critical Value\\n(p=0.001)'], \n",
    "            [chi_stat, critical_value],\n",
    "            color=['red' if has_srm else 'green', 'gray'],\n",
    "            alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax2.set_ylabel('Chi-Square Value', fontweight='bold')\n",
    "    ax2.set_title(f'Sample Ratio Mismatch Test\\n(p-value = {srm_p:.6f})', \n",
    "                  fontweight='bold', pad=15)\n",
    "    ax2.axhline(critical_value, color='red', linestyle='--', \n",
    "                linewidth=2, alpha=0.7, label='Threshold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    interp = \"FAIL - Investigate!\" if has_srm else \"PASS\"\n",
    "    interp_color = 'red' if has_srm else 'green'\n",
    "    ax2.text(0.5, 0.95, interp, transform=ax2.transAxes,\n",
    "            ha='center', va='top', fontsize=11, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor=interp_color, alpha=0.3))\n",
    "    \n",
    "    # Chart 3: Split Deviation Over Time Simulation\n",
    "    sample_sizes = np.logspace(2, np.log10(max(1000, actual * 10000)), 100)\n",
    "    expected_std = np.sqrt(expected * (1-expected) / sample_sizes)\n",
    "    \n",
    "    ax3.fill_between(sample_sizes, \n",
    "                     (expected - 2*expected_std) * 100,\n",
    "                     (expected + 2*expected_std) * 100,\n",
    "                     alpha=0.3, color='gray', label='±2 SD (95% CI)')\n",
    "    ax3.fill_between(sample_sizes,\n",
    "                     (expected - 3*expected_std) * 100,\n",
    "                     (expected + 3*expected_std) * 100,\n",
    "                     alpha=0.2, color='gray', label='±3 SD (99.7% CI)')\n",
    "    \n",
    "    ax3.axhline(expected * 100, color='blue', linestyle='--', \n",
    "                linewidth=2, label='Expected Split')\n",
    "    ax3.axhline(actual * 100, color='red' if has_srm else 'green', \n",
    "                linewidth=3, label=f'Actual Split ({actual*100:.2f}%)')\n",
    "    \n",
    "    ax3.set_xlabel('Sample Size', fontweight='bold')\n",
    "    ax3.set_ylabel('Control Group %', fontweight='bold')\n",
    "    ax3.set_title('Split Stability Analysis', fontweight='bold', pad=15)\n",
    "    ax3.set_xscale('log')\n",
    "    ax3.legend(loc='best', fontsize=9)\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # Chart 4: Independence Score Summary\n",
    "    scores = []\n",
    "    labels = []\n",
    "    colors = []\n",
    "    \n",
    "    srm_score = 100 if not has_srm else 0\n",
    "    scores.append(srm_score)\n",
    "    labels.append('SRM\\nCheck')\n",
    "    colors.append('green' if srm_score == 100 else 'red')\n",
    "    \n",
    "    deviation = abs(actual - expected)\n",
    "    balance_score = max(0, 100 - (deviation / 0.02) * 100)\n",
    "    scores.append(balance_score)\n",
    "    labels.append('Split\\nBalance')\n",
    "    colors.append('green' if balance_score > 80 else 'orange' if balance_score > 50 else 'red')\n",
    "    \n",
    "    overlap = randomization_assessment['user_overlap_pct']\n",
    "    overlap_score = max(0, 100 - overlap * 10)\n",
    "    scores.append(overlap_score)\n",
    "    labels.append('User\\nIndependence')\n",
    "    colors.append('green' if overlap_score > 80 else 'orange' if overlap_score > 50 else 'red')\n",
    "    \n",
    "    overall_score = np.mean(scores)\n",
    "    scores.append(overall_score)\n",
    "    labels.append('OVERALL')\n",
    "    colors.append('green' if overall_score > 80 else 'orange' if overall_score > 50 else 'red')\n",
    "    \n",
    "    bars = ax4.bar(labels, scores, color=colors, alpha=0.7, \n",
    "                   edgecolor='black', linewidth=2)\n",
    "    \n",
    "    for bar, score in zip(bars, scores):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, height + 2,\n",
    "                f'{score:.0f}', ha='center', va='bottom',\n",
    "                fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax4.axhline(80, color='green', linestyle='--', alpha=0.5, linewidth=2)\n",
    "    ax4.axhline(50, color='orange', linestyle='--', alpha=0.5, linewidth=2)\n",
    "    ax4.set_ylabel('Quality Score (0-100)', fontweight='bold')\n",
    "    ax4.set_title('Randomization Quality Scores', fontweight='bold', pad=15)\n",
    "    ax4.set_ylim(0, 110)\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    if overall_score >= 90:\n",
    "        grade = 'A - Excellent'\n",
    "        grade_color = 'green'\n",
    "    elif overall_score >= 80:\n",
    "        grade = 'B - Good'\n",
    "        grade_color = 'lightgreen'\n",
    "    elif overall_score >= 70:\n",
    "        grade = 'C - Fair'\n",
    "        grade_color = 'yellow'\n",
    "    elif overall_score >= 60:\n",
    "        grade = 'D - Poor'\n",
    "        grade_color = 'orange'\n",
    "    else:\n",
    "        grade = 'F - Failed'\n",
    "        grade_color = 'red'\n",
    "    \n",
    "    ax4.text(0.5, 0.5, grade, transform=ax4.transAxes,\n",
    "            ha='center', va='center', fontsize=16, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round,pad=0.8', facecolor=grade_color, alpha=0.4))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def assess_test_duration(duration_days, avg_session_days, sample_size):\n",
    "    \"\"\"Assess whether test duration is adequate\"\"\"\n",
    "    warnings = []\n",
    "    recommendations = []\n",
    "    \n",
    "    if duration_days < 7:\n",
    "        warnings.append(\"⚠️ Test duration is less than 1 week - may not capture weekly patterns\")\n",
    "        recommendations.append(\"Run for at least 7 days (ideally 14) to capture full week cycles\")\n",
    "    \n",
    "    full_weeks = duration_days / 7\n",
    "    if full_weeks < 2 and duration_days >= 7:\n",
    "        warnings.append(\"⚠️ Test has not run for 2 complete weeks - results may be biased by day-of-week effects\")\n",
    "        recommendations.append(\"Run for at least 2 full weeks for more reliable results\")\n",
    "    \n",
    "    min_duration_for_independence = avg_session_days * 3\n",
    "    if duration_days < min_duration_for_independence:\n",
    "        warnings.append(f\"⚠️ Test may not have enough time for user independence (recommended: {min_duration_for_independence:.0f}+ days)\")\n",
    "        recommendations.append(f\"With users returning every {avg_session_days:.1f} days, run for at least {min_duration_for_independence:.0f} days\")\n",
    "    \n",
    "    daily_visitors = sample_size / duration_days if duration_days > 0 else 0\n",
    "    \n",
    "    if daily_visitors > 2000 and duration_days < 7:\n",
    "        warnings.append(\"⚠️ High traffic but short duration - consider extending test\")\n",
    "        recommendations.append(\"You have good traffic volume - running longer will increase confidence\")\n",
    "    \n",
    "    validations = []\n",
    "    if duration_days >= 14:\n",
    "        validations.append(\"✓ Test ran for 2+ weeks - good coverage of weekly patterns\")\n",
    "    if duration_days >= min_duration_for_independence:\n",
    "        validations.append(\"✓ Test duration allows for user independence\")\n",
    "    if full_weeks >= 2:\n",
    "        validations.append(\"✓ Multiple complete week cycles captured\")\n",
    "    \n",
    "    return {\n",
    "        'warnings': warnings,\n",
    "        'recommendations': recommendations,\n",
    "        'validations': validations,\n",
    "        'full_weeks': full_weeks,\n",
    "        'daily_visitors': daily_visitors,\n",
    "        'independence_score': min(1.0, duration_days / min_duration_for_independence)\n",
    "    }\n",
    "\n",
    "def display_results(results, title=\"Overall Results\", is_segment=False, duration_assessment=None):\n",
    "    \"\"\"Display results for overall or segment\"\"\"\n",
    "    if results is None:\n",
    "        return\n",
    "        \n",
    "    ci = int(results['confidence_level'] * 100)\n",
    "    \n",
    "    if not is_segment:\n",
    "        display(HTML(f\"<h2>{title}</h2><hr>\"))\n",
    "    else:\n",
    "        display(HTML(f\"<h3 style='color: #495057;'>{title}</h3>\"))\n",
    "    \n",
    "    # Test Duration Assessment (only for overall results)\n",
    "    if duration_assessment and not is_segment:\n",
    "        display(HTML(\"<h3>⏱️ Test Duration Assessment</h3>\"))\n",
    "        display(HTML(\"\"\"\n",
    "        <div class='help-text'>\n",
    "            <strong>What This Section Shows:</strong><br>\n",
    "            This checks if your test ran long enough to give reliable results. Tests that are too short \n",
    "            can be influenced by random daily variations or unusual events.\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        duration_html = f\"\"\"\n",
    "        <div class=\"info-box\">\n",
    "            <p><strong>Test Duration:</strong> {test_duration_days.value} days ({duration_assessment['full_weeks']:.1f} weeks)</p>\n",
    "            <p><strong>Daily Visitors per Group:</strong> {duration_assessment['daily_visitors']:,.0f}</p>\n",
    "            <p><strong>User Independence Score:</strong> {duration_assessment['independence_score']*100:.0f}% \n",
    "            <span style='color:#666;font-size:12px;'>(Higher is better - means users likely saw only one version)</span></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(duration_html))\n",
    "        \n",
    "        if duration_assessment['validations']:\n",
    "            val_html = \"<div class='success-box'><h4>✓ Duration Validations</h4><ul>\"\n",
    "            for val in duration_assessment['validations']:\n",
    "                val_html += f\"<li>{val}</li>\"\n",
    "            val_html += \"</ul></div>\"\n",
    "            display(HTML(val_html))\n",
    "        \n",
    "        if duration_assessment['warnings']:\n",
    "            warn_html = \"<div class='warning-box'><h4>⚠️ Duration Warnings</h4><ul>\"\n",
    "            for warn in duration_assessment['warnings']:\n",
    "                warn_html += f\"<li>{warn}</li>\"\n",
    "            warn_html += \"</ul></div>\"\n",
    "            display(HTML(warn_html))\n",
    "        \n",
    "        if duration_assessment['recommendations']:\n",
    "            rec_html = \"<div class='info-box'><h4>\uD83D\uDCA1 Recommendations</h4><ul>\"\n",
    "            for rec in duration_assessment['recommendations']:\n",
    "                rec_html += f\"<li>{rec}</li>\"\n",
    "            rec_html += \"</ul></div>\"\n",
    "            display(HTML(rec_html))\n",
    "        \n",
    "        display(HTML(\"<hr>\"))\n",
    "    \n",
    "    # Top metrics\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style='display: flex; justify-content: space-around; margin: 20px 0;'>\n",
    "        <div style='text-align: center; padding: 15px; background-color: #e3f2fd; border-radius: 10px; flex: 1; margin: 0 5px;'>\n",
    "            <div style='font-size: 12px; color: #666;'>Control Rate</div>\n",
    "            <div style='font-size: 20px; font-weight: bold; color: #1976d2;'>{results['control_rate']*100:.2f}%</div>\n",
    "            <div style='font-size: 11px; color: #666; margin-top: 5px;'>Original version<br>performance</div>\n",
    "        </div>\n",
    "        <div style='text-align: center; padding: 15px; background-color: #e8f5e9; border-radius: 10px; flex: 1; margin: 0 5px;'>\n",
    "            <div style='font-size: 12px; color: #666;'>Treatment Rate</div>\n",
    "            <div style='font-size: 20px; font-weight: bold; color: #388e3c;'>{results['treatment_rate']*100:.2f}%</div>\n",
    "            <div style='font-size: 11px; color: #666; margin-top: 5px;'>New version<br>({results['lift_abs']*100:+.2f} percentage points)</div>\n",
    "        </div>\n",
    "        <div style='text-align: center; padding: 15px; background-color: #f3e5f5; border-radius: 10px; flex: 1; margin: 0 5px;'>\n",
    "            <div style='font-size: 12px; color: #666;'>Relative Lift</div>\n",
    "            <div style='font-size: 20px; font-weight: bold; color: #7b1fa2;'>{results['lift_rel']:.2f}%</div>\n",
    "            <div style='font-size: 11px; color: #666; margin-top: 5px;'>Percentage<br>improvement</div>\n",
    "        </div>\n",
    "        <div style='text-align: center; padding: 15px; background-color: #fff3e0; border-radius: 10px; flex: 1; margin: 0 5px;'>\n",
    "            <div style='font-size: 12px; color: #666;'>P-Value</div>\n",
    "            <div style='font-size: 20px; font-weight: bold; color: #f57c00;'>{results['p_value']:.4f}</div>\n",
    "            <div style='font-size: 11px; color: #666; margin-top: 5px;'>{\"Significant ✓\" if results['is_significant'] else \"Not Significant ✗\"}</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "    \n",
    "    # Add explanations for key metrics\n",
    "    if not is_segment:\n",
    "        display(HTML(\"\"\"\n",
    "        <div class='help-text'>\n",
    "            <strong>\uD83D\uDCCC Understanding These Numbers:</strong><br>\n",
    "            • <strong>Control Rate:</strong> What % of Control users converted (e.g., 12% = 12 out of 100 made a purchase)<br>\n",
    "            • <strong>Treatment Rate:</strong> What % of Treatment users converted<br>\n",
    "            • <strong>Relative Lift:</strong> How much better (or worse) Treatment performed vs. Control as a percentage<br>\n",
    "            • <strong>P-Value:</strong> The probability your results are due to random chance. Lower = better! \n",
    "            Under 0.05 (5%) is typically considered \"significant\"\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    # Significance status\n",
    "    if results['is_significant'] and results['lift_rel'] > 0:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div class=\"success-box\" style=\"font-size: 14px;\">\n",
    "            <strong>✅ STATISTICALLY SIGNIFICANT (Positive Result)</strong><br>\n",
    "            <span style='font-size:13px;'>P-Value: {results['p_value']:.4f} | Z-Statistic: {results['z_stat']:.3f}</span><br><br>\n",
    "            <strong>What this means:</strong> The Treatment version is genuinely better than Control. \n",
    "            This result is very unlikely to be due to random chance (less than {results['alpha']*100:.0f}% probability).\n",
    "            You can confidently roll out the Treatment version to all users.\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    elif results['is_significant'] and results['lift_rel'] < 0:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div class=\"danger-box\" style=\"font-size: 14px;\">\n",
    "            <strong>❌ STATISTICALLY SIGNIFICANT (Negative Result)</strong><br>\n",
    "            <span style='font-size:13px;'>P-Value: {results['p_value']:.4f} | Z-Statistic: {results['z_stat']:.3f}</span><br><br>\n",
    "            <strong>What this means:</strong> The Treatment version performs WORSE than Control. \n",
    "            This result is very unlikely to be due to random chance. \n",
    "            <strong>Recommendation:</strong> Keep using the Control version or try a different approach.\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    else:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div class=\"warning-box\" style=\"font-size: 14px;\">\n",
    "            <strong>⚠️ NOT STATISTICALLY SIGNIFICANT (Inconclusive)</strong><br>\n",
    "            <span style='font-size:13px;'>P-Value: {results['p_value']:.4f} | Z-Statistic: {results['z_stat']:.3f}</span><br><br>\n",
    "            <strong>What this means:</strong> The difference between Control and Treatment could easily be due to random chance. \n",
    "            We can't confidently say one is better than the other.<br>\n",
    "            <strong>Recommendation:</strong> Either run the test longer to gather more data, or conclude that the change doesn't \n",
    "            have a meaningful impact.\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "    \n",
    "    # CI and Revenue (only for overall)\n",
    "    if not is_segment:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style='display: flex; gap: 20px; margin: 20px 0;'>\n",
    "            <div class=\"info-box\" style='flex: 1;'>\n",
    "                <h4>{ci}% Confidence Interval</h4>\n",
    "                <p><strong>Range:</strong> [{results['ci_lower']*100:.2f}%, {results['ci_upper']*100:.2f}%]</p>\n",
    "                <p><strong>Interpretation:</strong> {\n",
    "                    \"✓ Treatment is better with high confidence\" if results['ci_lower'] > 0 \n",
    "                    else \"✗ Treatment is worse with high confidence\" if results['ci_upper'] < 0 \n",
    "                    else \"⚠ Inconclusive - the true effect could be positive, negative, or zero\"\n",
    "                }</p>\n",
    "                <p style='font-size:12px;color:#666;margin-top:10px;'>\n",
    "                    <strong>What is a Confidence Interval?</strong><br>\n",
    "                    We're {ci}% confident that the true lift falls somewhere in this range. \n",
    "                    If the range includes zero (crosses from negative to positive), we can't be sure of the direction of the effect.\n",
    "                </p>\n",
    "            </div>\n",
    "            <div style='flex: 1; background-color: {\"#d4edda\" if results[\"revenue_impact\"] >= 0 else \"#f8d7da\"}; \n",
    "                 padding: 20px; border-radius: 10px; text-align: center;'>\n",
    "                <h4 style='margin-top: 0;'>Annual Revenue Impact</h4>\n",
    "                <h2 style=\"color: {\"#28a745\" if results[\"revenue_impact\"] >= 0 else \"#dc3545\"}; margin: 10px 0;\">\n",
    "                    ${results['revenue_impact']:,.2f}\n",
    "                </h2>\n",
    "                <p style='font-size:12px;color:#666;margin-top:10px;'>\n",
    "                    <strong>What this means:</strong><br>\n",
    "                    If you roll out the Treatment to everyone, this is the estimated additional \n",
    "                    (or lost) revenue per year based on your current traffic and monthly revenue.\n",
    "                </p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "def create_statistical_distribution_viz(results, ci):\n",
    "    \"\"\"Create statistical distribution visualization showing significance\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    z_stat = results['z_stat']\n",
    "    p_value = results['p_value']\n",
    "    alpha = results['alpha']\n",
    "    z_critical = results['z_critical']\n",
    "    lift_abs = results['lift_abs']\n",
    "    ci_lower = results['ci_lower']\n",
    "    ci_upper = results['ci_upper']\n",
    "    \n",
    "    # Chart 1: Null Distribution with Test Statistic\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = stats.norm.pdf(x, 0, 1)\n",
    "    \n",
    "    ax1.plot(x, y, 'b-', linewidth=2, label='Null Distribution')\n",
    "    ax1.fill_between(x, 0, y, where=(x <= -z_critical), alpha=0.3, color='red', \n",
    "                     label=f'Rejection Region (α/2 = {alpha/2:.3f})')\n",
    "    ax1.fill_between(x, 0, y, where=(x >= z_critical), alpha=0.3, color='red')\n",
    "    \n",
    "    ax1.axvline(z_stat, color='green' if results['is_significant'] else 'orange', \n",
    "                linewidth=3, linestyle='--', label=f'Observed Z = {z_stat:.3f}')\n",
    "    ax1.axvline(-z_critical, color='red', linewidth=2, linestyle=':')\n",
    "    ax1.axvline(z_critical, color='red', linewidth=2, linestyle=':', label=f'Critical Z = ±{z_critical:.3f}')\n",
    "    \n",
    "    ax1.set_xlabel('Z-Score', fontweight='bold')\n",
    "    ax1.set_ylabel('Probability Density', fontweight='bold')\n",
    "    ax1.set_title('Null Hypothesis Distribution\\n(Two-Tailed Test)', fontweight='bold', pad=10)\n",
    "    ax1.legend(loc='upper right', fontsize=9)\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    sig_text = \"SIGNIFICANT\" if results['is_significant'] else \"NOT SIGNIFICANT\"\n",
    "    sig_color = \"green\" if results['is_significant'] else \"orange\"\n",
    "    ax1.text(0.5, 0.95, sig_text, transform=ax1.transAxes, \n",
    "             ha='center', va='top', fontsize=12, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor=sig_color, alpha=0.3))\n",
    "    \n",
    "    # Chart 2: P-Value Visualization\n",
    "    x_tail = np.linspace(-4, 4, 1000)\n",
    "    y_tail = stats.norm.pdf(x_tail, 0, 1)\n",
    "    \n",
    "    ax2.plot(x_tail, y_tail, 'b-', linewidth=2)\n",
    "    \n",
    "    if z_stat > 0:\n",
    "        ax2.fill_between(x_tail, 0, y_tail, where=(x_tail >= abs(z_stat)), \n",
    "                        alpha=0.5, color='purple', label=f'P-value = {p_value:.4f}')\n",
    "        ax2.fill_between(x_tail, 0, y_tail, where=(x_tail <= -abs(z_stat)), \n",
    "                        alpha=0.5, color='purple')\n",
    "    else:\n",
    "        ax2.fill_between(x_tail, 0, y_tail, where=(x_tail <= z_stat), \n",
    "                        alpha=0.5, color='purple', label=f'P-value = {p_value:.4f}')\n",
    "        ax2.fill_between(x_tail, 0, y_tail, where=(x_tail >= -z_stat), \n",
    "                        alpha=0.5, color='purple')\n",
    "    \n",
    "    ax2.axvline(z_stat, color='green' if results['is_significant'] else 'orange', \n",
    "                linewidth=3, linestyle='--')\n",
    "    ax2.axhline(alpha, color='red', linewidth=2, linestyle=':', \n",
    "                label=f'Alpha = {alpha:.3f}')\n",
    "    \n",
    "    ax2.set_xlabel('Z-Score', fontweight='bold')\n",
    "    ax2.set_ylabel('Probability Density', fontweight='bold')\n",
    "    ax2.set_title(f'P-Value Visualization\\nP-value {\"<\" if p_value < alpha else \"≥\"} α', \n",
    "                  fontweight='bold', pad=10)\n",
    "    ax2.legend(loc='upper right', fontsize=9)\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Chart 3: Confidence Interval on Lift Distribution\n",
    "    se = results['lift_abs'] / results['z_stat'] if results['z_stat'] != 0 else 0.001\n",
    "    x_lift = np.linspace(lift_abs - 4*se, lift_abs + 4*se, 1000)\n",
    "    y_lift = stats.norm.pdf(x_lift, lift_abs, se)\n",
    "    \n",
    "    ax3.plot(x_lift * 100, y_lift, 'b-', linewidth=2, label='Sampling Distribution')\n",
    "    \n",
    "    ci_mask = (x_lift >= ci_lower) & (x_lift <= ci_upper)\n",
    "    ax3.fill_between(x_lift * 100, 0, y_lift, where=ci_mask, \n",
    "                     alpha=0.4, color='green', label=f'{ci}% Confidence Interval')\n",
    "    \n",
    "    ax3.axvline(lift_abs * 100, color='blue', linewidth=3, linestyle='-', \n",
    "                label=f'Point Estimate = {lift_abs*100:.2f}pp')\n",
    "    ax3.axvline(0, color='red', linewidth=2, linestyle='--', \n",
    "                label='No Effect (H₀)', alpha=0.7)\n",
    "    ax3.axvline(ci_lower * 100, color='green', linewidth=2, linestyle=':', alpha=0.7)\n",
    "    ax3.axvline(ci_upper * 100, color='green', linewidth=2, linestyle=':', alpha=0.7)\n",
    "    \n",
    "    ax3.set_xlabel('Lift (percentage points)', fontweight='bold')\n",
    "    ax3.set_ylabel('Probability Density', fontweight='bold')\n",
    "    ax3.set_title(f'{ci}% Confidence Interval for Lift\\n[{ci_lower*100:.2f}pp, {ci_upper*100:.2f}pp]', \n",
    "                  fontweight='bold', pad=10)\n",
    "    ax3.legend(loc='upper right', fontsize=9)\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    if ci_lower > 0:\n",
    "        interp = \"CI excludes zero → Treatment is better\"\n",
    "        interp_color = 'green'\n",
    "    elif ci_upper < 0:\n",
    "        interp = \"CI excludes zero → Treatment is worse\"\n",
    "        interp_color = 'red'\n",
    "    else:\n",
    "        interp = \"CI includes zero → Inconclusive\"\n",
    "        interp_color = 'orange'\n",
    "    \n",
    "    ax3.text(0.5, 0.95, interp, transform=ax3.transAxes, \n",
    "             ha='center', va='top', fontsize=10, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor=interp_color, alpha=0.3))\n",
    "    \n",
    "    # Chart 4: Effect Size and Power Visualization\n",
    "    effect_size = lift_abs / se if se > 0 else 0\n",
    "    x_power = np.linspace(-4, 8, 1000)\n",
    "    \n",
    "    y_null = stats.norm.pdf(x_power, 0, 1)\n",
    "    ax4.plot(x_power, y_null, 'b-', linewidth=2, label='Null (H₀)', alpha=0.7)\n",
    "    ax4.fill_between(x_power, 0, y_null, where=(x_power >= z_critical), \n",
    "                     alpha=0.2, color='red', label='Type I Error Region (α)')\n",
    "    \n",
    "    y_alt = stats.norm.pdf(x_power, effect_size, 1)\n",
    "    ax4.plot(x_power, y_alt, 'g-', linewidth=2, label=f'Alternative (H₁)', alpha=0.7)\n",
    "    ax4.fill_between(x_power, 0, y_alt, where=(x_power >= z_critical), \n",
    "                     alpha=0.3, color='green', label='Power (1-β)')\n",
    "    ax4.fill_between(x_power, 0, y_alt, where=(x_power < z_critical), \n",
    "                     alpha=0.2, color='orange', label='Type II Error (β)')\n",
    "    \n",
    "    ax4.axvline(z_critical, color='red', linewidth=2, linestyle='--', \n",
    "                label=f'Critical Value = {z_critical:.3f}')\n",
    "    ax4.axvline(z_stat, color='purple', linewidth=3, linestyle=':', \n",
    "                label=f'Observed = {z_stat:.3f}')\n",
    "    \n",
    "    power = 1 - stats.norm.cdf(z_critical - effect_size)\n",
    "    \n",
    "    ax4.set_xlabel('Z-Score', fontweight='bold')\n",
    "    ax4.set_ylabel('Probability Density', fontweight='bold')\n",
    "    ax4.set_title(f'Statistical Power Visualization\\nEstimated Power ≈ {power*100:.1f}%', \n",
    "                  fontweight='bold', pad=10)\n",
    "    ax4.legend(loc='upper right', fontsize=8)\n",
    "    ax4.grid(alpha=0.3)\n",
    "    ax4.set_xlim(-4, 8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_segment_comparison_chart(segment_results, ci):\n",
    "    \"\"\"Create comparison chart across segments\"\"\"\n",
    "    if not segment_results:\n",
    "        return\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    segments = [r['name'] for r in segment_results]\n",
    "    ctrl_rates = [r['results']['control_rate'] * 100 for r in segment_results]\n",
    "    treat_rates = [r['results']['treatment_rate'] * 100 for r in segment_results]\n",
    "    lifts = [r['results']['lift_rel'] for r in segment_results]\n",
    "    is_sig = [r['results']['is_significant'] for r in segment_results]\n",
    "    \n",
    "    x = np.arange(len(segments))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Chart 1: Conversion Rates\n",
    "    bars1 = ax1.bar(x - width/2, ctrl_rates, width, label='Control', color='#1976d2', alpha=0.8)\n",
    "    bars2 = ax1.bar(x + width/2, treat_rates, width, label='Treatment', color='#388e3c', alpha=0.8)\n",
    "    \n",
    "    ax1.set_ylabel('Conversion Rate (%)', fontweight='bold')\n",
    "    ax1.set_title('Conversion Rates by Segment', fontweight='bold', pad=15)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(segments, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Chart 2: Relative Lift\n",
    "    colors = ['#28a745' if sig and lift > 0 else '#dc3545' if sig and lift < 0 else '#ffc107' \n",
    "              for sig, lift in zip(is_sig, lifts)]\n",
    "    bars = ax2.bar(segments, lifts, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax2.axhline(0, color='black', linewidth=1, linestyle='--', alpha=0.5)\n",
    "    ax2.set_ylabel('Relative Lift (%)', fontweight='bold')\n",
    "    ax2.set_title('Relative Lift by Segment', fontweight='bold', pad=15)\n",
    "    ax2.set_xticklabels(segments, rotation=45, ha='right')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, lift, sig in zip(bars, lifts, is_sig):\n",
    "        height = bar.get_height()\n",
    "        label = f'{lift:.1f}%' + (' *' if sig else '')\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2, height,\n",
    "                label, ha='center', va='bottom' if height > 0 else 'top',\n",
    "                fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_segment_summary_table(segment_results):\n",
    "    \"\"\"Create summary table for all segments\"\"\"\n",
    "    if not segment_results:\n",
    "        return\n",
    "    \n",
    "    data = []\n",
    "    for seg in segment_results:\n",
    "        r = seg['results']\n",
    "        data.append({\n",
    "            'Segment': seg['name'],\n",
    "            'Control Rate': f\"{r['control_rate']*100:.2f}%\",\n",
    "            'Treatment Rate': f\"{r['treatment_rate']*100:.2f}%\",\n",
    "            'Lift (Abs)': f\"{r['lift_abs']*100:.2f}pp\",\n",
    "            'Lift (Rel)': f\"{r['lift_rel']:.1f}%\",\n",
    "            'P-Value': f\"{r['p_value']:.4f}\",\n",
    "            'Significant': \"Yes ✓\" if r['is_significant'] else \"No ✗\",\n",
    "            'Sample Size': f\"{r['current_n']:,}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    display(HTML(\"<h3>\uD83D\uDCCB Segment Summary Table</h3>\"))\n",
    "    display(df)\n",
    "\n",
    "# Button click handler\n",
    "def on_calculate_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        \n",
    "        ci = ci_selector.value\n",
    "        \n",
    "        # Calculate overall results\n",
    "        display(HTML(\"<h2>\uD83D\uDCC8 Test Results</h2><hr>\"))\n",
    "        \n",
    "        overall_results = calculate_ab_test(\n",
    "            ci, \n",
    "            control_visitors.value, \n",
    "            control_conversions.value,\n",
    "            treatment_visitors.value, \n",
    "            treatment_conversions.value,\n",
    "            current_revenue.value, \n",
    "            seasonal_multiplier.value\n",
    "        )\n",
    "        \n",
    "        # Assess test duration\n",
    "        duration_assessment = assess_test_duration(\n",
    "            test_duration_days.value,\n",
    "            average_session_days.value,\n",
    "            control_visitors.value\n",
    "        )\n",
    "        \n",
    "        # Assess randomization quality\n",
    "        randomization_assessment = assess_randomization_quality(\n",
    "            control_visitors.value,\n",
    "            treatment_visitors.value,\n",
    "            expected_split.value,\n",
    "            user_overlap_pct.value\n",
    "        )\n",
    "        \n",
    "        if overall_results:\n",
    "            display_results(overall_results, \"Overall Results\", is_segment=False, duration_assessment=duration_assessment)\n",
    "            \n",
    "            # Add randomization quality assessment\n",
    "            display(HTML(\"<br><h3>\uD83C\uDFB2 Randomization Quality Assessment</h3>\"))\n",
    "            display(HTML(\"\"\"\n",
    "            <div class='help-text'>\n",
    "                <strong>What This Section Shows:</strong><br>\n",
    "                This checks if your test was set up properly. A good test randomly assigns users to Control vs. Treatment \n",
    "                in a fair way. If there are problems here, your results might not be trustworthy even if they look significant.\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            \n",
    "            # Display assessment results\n",
    "            if randomization_assessment['validations']:\n",
    "                val_html = \"<div class='success-box'><h4>✓ Validations</h4><ul>\"\n",
    "                for val in randomization_assessment['validations']:\n",
    "                    val_html += f\"<li>{val}</li>\"\n",
    "                val_html += \"</ul></div>\"\n",
    "                display(HTML(val_html))\n",
    "            \n",
    "            if randomization_assessment['warnings']:\n",
    "                warn_html = \"<div class='warning-box' if not randomization_assessment['has_srm'] else 'danger-box'><h4>⚠️ Warnings</h4><ul>\"\n",
    "                for warn in randomization_assessment['warnings']:\n",
    "                    warn_html += f\"<li>{warn}</li>\"\n",
    "                warn_html += \"</ul></div>\"\n",
    "                display(HTML(warn_html))\n",
    "            \n",
    "            if randomization_assessment['recommendations']:\n",
    "                rec_html = \"<div class='info-box'><h4>\uD83D\uDCA1 Recommendations</h4><ul>\"\n",
    "                for rec in randomization_assessment['recommendations']:\n",
    "                    rec_html += f\"<li>{rec}</li>\"\n",
    "                rec_html += \"</ul></div>\"\n",
    "                display(HTML(rec_html))\n",
    "            \n",
    "            # Visualizations\n",
    "            display(HTML(\"\"\"\n",
    "            <div class='help-text'>\n",
    "                <strong>\uD83D\uDCCA Charts Below Explain:</strong><br>\n",
    "                • <strong>Chart 1:</strong> Did your traffic split the way you intended?<br>\n",
    "                • <strong>Chart 2:</strong> Statistical test for Sample Ratio Mismatch (technical problem detector)<br>\n",
    "                • <strong>Chart 3:</strong> How normal variation affects split ratios at different sample sizes<br>\n",
    "                • <strong>Chart 4:</strong> Overall quality grade for your test setup\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            create_randomization_viz(randomization_assessment)\n",
    "            \n",
    "            # Add statistical distribution visualizations\n",
    "            display(HTML(\"<br><h3>\uD83D\uDCCA Statistical Distribution Analysis</h3>\"))\n",
    "            display(HTML(\"\"\"\n",
    "            <div class='help-text'>\n",
    "                <strong>What This Section Shows:</strong><br>\n",
    "                These charts show the statistical math behind your results. Don't worry if they look complex - \n",
    "                the key takeaways are explained in the text above.<br><br>\n",
    "                <strong>Key Concepts:</strong><br>\n",
    "                • <strong>Null Hypothesis (H₀):</strong> The assumption that there's NO real difference between Control and Treatment<br>\n",
    "                • <strong>Alternative Hypothesis (H₁):</strong> The claim that there IS a real difference<br>\n",
    "                • <strong>Z-Score:</strong> How many \"standard deviations\" away your result is from what we'd expect by chance<br>\n",
    "                • <strong>P-Value:</strong> Probability that results this extreme could happen by random luck alone\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            create_statistical_distribution_viz(overall_results, ci)\n",
    "        \n",
    "        # Calculate segment results if enabled\n",
    "        if enable_segmentation.value and segment_widgets:\n",
    "            display(HTML(\"<br><hr><h2>\uD83D\uDD0D Segment Analysis</h2><hr>\"))\n",
    "            display(HTML(\"\"\"\n",
    "            <div class='help-text'>\n",
    "                <strong>What Segment Analysis Shows:</strong><br>\n",
    "                This breaks down your results by different user groups. You might find that your Treatment works \n",
    "                great for some segments but not others - this is valuable insight!<br><br>\n",
    "                <strong>Example:</strong> Your new mobile app design might boost conversions for new users (+15%) \n",
    "                but actually hurt conversions for existing users (-5%). Without segment analysis, you'd only see \n",
    "                the average and miss this important pattern.\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "            \n",
    "            segment_results = []\n",
    "            for i, widgets_dict in segment_widgets.items():\n",
    "                seg_name = widgets_dict['name'].value\n",
    "                ctrl_v = widgets_dict['ctrl_v'].value\n",
    "                ctrl_c = widgets_dict['ctrl_c'].value\n",
    "                treat_v = widgets_dict['treat_v'].value\n",
    "                treat_c = widgets_dict['treat_c'].value\n",
    "                \n",
    "                seg_results = calculate_ab_test(\n",
    "                    ci, ctrl_v, ctrl_c, treat_v, treat_c,\n",
    "                    current_revenue.value, seasonal_multiplier.value\n",
    "                )\n",
    "                \n",
    "                if seg_results:\n",
    "                    segment_results.append({\n",
    "                        'name': seg_name,\n",
    "                        'results': seg_results\n",
    "                    })\n",
    "                    display(HTML(f\"<div class='segment-box'>\"))\n",
    "                    display_results(seg_results, f\"\uD83D\uDCCA {seg_name}\", is_segment=True)\n",
    "                    display(HTML(\"</div>\"))\n",
    "            \n",
    "            # Segment comparison visualizations\n",
    "            if segment_results:\n",
    "                display(HTML(\"<br><h3>\uD83D\uDCCA Segment Comparison</h3>\"))\n",
    "                display(HTML(\"\"\"\n",
    "                <div class='help-text'>\n",
    "                    <strong>How to Read These Charts:</strong><br>\n",
    "                    • <strong>Left Chart:</strong> Shows conversion rates for each segment. Higher bars = more conversions.<br>\n",
    "                    • <strong>Right Chart:</strong> Shows relative lift (% improvement). Green = Treatment won, Red = Control won, Yellow = Inconclusive.<br>\n",
    "                    • <strong>Asterisk (*):</strong> Marks segments where the result is statistically significant.\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                create_segment_comparison_chart(segment_results, ci)\n",
    "                create_segment_summary_table(segment_results)\n",
    "                \n",
    "                # Insights\n",
    "                display(HTML(\"<br><h3>\uD83D\uDCA1 Segment Insights</h3>\"))\n",
    "                sig_positive = [s for s in segment_results if s['results']['is_significant'] and s['results']['lift_rel'] > 0]\n",
    "                sig_negative = [s for s in segment_results if s['results']['is_significant'] and s['results']['lift_rel'] < 0]\n",
    "                not_sig = [s for s in segment_results if not s['results']['is_significant']]\n",
    "                \n",
    "                insights_html = \"<div class='info-box'>\"\n",
    "                insights_html += f\"<p><strong>✅ Segments with Significant Positive Impact:</strong> {len(sig_positive)} of {len(segment_results)}</p>\"\n",
    "                if sig_positive:\n",
    "                    insights_html += \"<ul>\"\n",
    "                    for s in sig_positive:\n",
    "                        insights_html += f\"<li><strong>{s['name']}</strong>: {s['results']['lift_rel']:.1f}% lift (Treatment is better!)</li>\"\n",
    "                    insights_html += \"</ul>\"\n",
    "                else:\n",
    "                    insights_html += \"<p style='color:#666;margin-left:20px;'>No segments showed significant positive results.</p>\"\n",
    "                \n",
    "                if sig_negative:\n",
    "                    insights_html += f\"<p><strong>❌ Segments with Significant Negative Impact:</strong> {len(sig_negative)}</p><ul>\"\n",
    "                    for s in sig_negative:\n",
    "                        insights_html += f\"<li><strong>{s['name']}</strong>: {s['results']['lift_rel']:.1f}% lift (Control is better)</li>\"\n",
    "                    insights_html += \"</ul>\"\n",
    "                \n",
    "                if not_sig:\n",
    "                    insights_html += f\"<p><strong>⚠️ Segments with Inconclusive Results:</strong> {len(not_sig)}</p>\"\n",
    "                    insights_html += \"<p style='color:#666;margin-left:20px;'>These segments need more data or show no meaningful difference between Control and Treatment.</p>\"\n",
    "                \n",
    "                # Strategic recommendations\n",
    "                insights_html += \"<br><h4>\uD83D\uDCCB Strategic Recommendations:</h4>\"\n",
    "                \n",
    "                if len(sig_positive) > 0 and len(sig_negative) == 0:\n",
    "                    insights_html += \"<p style='color:#28a745;'><strong>Great news!</strong> Treatment shows positive results across segments where it's significant. Consider rolling it out to all users.</p>\"\n",
    "                elif len(sig_positive) > 0 and len(sig_negative) > 0:\n",
    "                    insights_html += \"<p style='color:#ffc107;'><strong>Mixed results:</strong> Treatment helps some segments but hurts others. Consider:</p>\"\n",
    "                    insights_html += \"<ul><li>Implementing Treatment only for segments where it performs well</li>\"\n",
    "                    insights_html += \"<li>Creating different experiences for different segments</li>\"\n",
    "                    insights_html += \"<li>Investigating why certain segments respond differently</li></ul>\"\n",
    "                elif len(sig_negative) > 0 and len(sig_positive) == 0:\n",
    "                    insights_html += \"<p style='color:#dc3545;'><strong>Caution:</strong> Treatment is underperforming in segments where we have clear results. Stick with Control or redesign the Treatment.</p>\"\n",
    "                else:\n",
    "                    insights_html += \"<p style='color:#666;'>No clear winners yet. Either continue testing for more data or conclude that the changes don't have a strong impact.</p>\"\n",
    "                \n",
    "                insights_html += \"</div>\"\n",
    "                display(HTML(insights_html))\n",
    "        \n",
    "        # Final summary and next steps\n",
    "        if overall_results:\n",
    "            display(HTML(\"<br><hr><h2>\uD83D\uDCDD Summary & Next Steps</h2>\"))\n",
    "            \n",
    "            summary_html = \"<div class='info-box'>\"\n",
    "            summary_html += \"<h4>Your Test at a Glance:</h4>\"\n",
    "            summary_html += f\"<p>• <strong>Overall Result:</strong> {'✅ Significant' if overall_results['is_significant'] else '⚠️ Not Significant'}</p>\"\n",
    "            summary_html += f\"<p>• <strong>Conversion Improvement:</strong> {overall_results['lift_rel']:+.2f}%</p>\"\n",
    "            summary_html += f\"<p>• <strong>Confidence:</strong> {int(overall_results['confidence_level']*100)}%</p>\"\n",
    "            summary_html += f\"<p>• <strong>Potential Annual Revenue Impact:</strong> ${overall_results['revenue_impact']:,.2f}</p>\"\n",
    "            \n",
    "            summary_html += \"<br><h4>What Should You Do Next?</h4>\"\n",
    "            \n",
    "            if overall_results['is_significant'] and overall_results['lift_rel'] > 0:\n",
    "                summary_html += \"<div class='success-box'>\"\n",
    "                summary_html += \"<p><strong>✅ Recommended Action: LAUNCH</strong></p>\"\n",
    "                summary_html += \"<p>Your test shows a clear winner! The Treatment version performs significantly better than Control. \"\n",
    "                summary_html += \"You can confidently roll it out to all users.</p>\"\n",
    "                summary_html += \"<p><strong>Before launching:</strong></p>\"\n",
    "                summary_html += \"<ul>\"\n",
    "                summary_html += \"<li>✓ Make sure your randomization quality scores look good (check the grades above)</li>\"\n",
    "                summary_html += \"<li>✓ Review segment results to see if any groups need special consideration</li>\"\n",
    "                summary_html += \"<li>✓ Plan for monitoring post-launch to ensure results hold</li>\"\n",
    "                summary_html += \"</ul>\"\n",
    "                summary_html += \"</div>\"\n",
    "                \n",
    "            elif overall_results['is_significant'] and overall_results['lift_rel'] < 0:\n",
    "                summary_html += \"<div class='danger-box'>\"\n",
    "                summary_html += \"<p><strong>❌ Recommended Action: DO NOT LAUNCH</strong></p>\"\n",
    "                summary_html += \"<p>Your test shows that the Treatment actually performs WORSE than Control. \"\n",
    "                summary_html += \"Stick with your current version or go back to the drawing board with a new approach.</p>\"\n",
    "                summary_html += \"<p><strong>Next steps:</strong></p>\"\n",
    "                summary_html += \"<ul>\"\n",
    "                summary_html += \"<li>Analyze why the Treatment underperformed</li>\"\n",
    "                summary_html += \"<li>Gather user feedback or qualitative data</li>\"\n",
    "                summary_html += \"<li>Design a new Treatment that addresses the issues</li>\"\n",
    "                summary_html += \"</ul>\"\n",
    "                summary_html += \"</div>\"\n",
    "                \n",
    "            else:\n",
    "                summary_html += \"<div class='warning-box'>\"\n",
    "                summary_html += \"<p><strong>⚠️ Recommended Action: MORE DATA NEEDED or NEUTRAL RESULT</strong></p>\"\n",
    "                summary_html += \"<p>Your test results are inconclusive. The difference between Control and Treatment \"\n",
    "                summary_html += \"could easily be due to random chance.</p>\"\n",
    "                summary_html += \"<p><strong>You have two options:</strong></p>\"\n",
    "                summary_html += \"<ul>\"\n",
    "                summary_html += \"<li><strong>Option 1:</strong> Continue testing to gather more data (recommended if you see a promising trend)</li>\"\n",
    "                summary_html += \"<li><strong>Option 2:</strong> Conclude that the change doesn't have a meaningful impact and move on to other experiments</li>\"\n",
    "                summary_html += \"</ul>\"\n",
    "                summary_html += f\"<p><strong>Power calculation:</strong> With your current sample size of {overall_results['current_n']:,} per group, \"\n",
    "                summary_html += f\"you have good power to detect meaningful effects (2%+ lift). If no effect was found, it likely means the true impact is very small.</p>\"\n",
    "                summary_html += \"</div>\"\n",
    "            \n",
    "            summary_html += \"<br><h4>General Best Practices:</h4>\"\n",
    "            summary_html += \"<ul>\"\n",
    "            summary_html += \"<li>\uD83D\uDCCA Always check randomization quality before trusting your results</li>\"\n",
    "            summary_html += \"<li>⏱️ Run tests for at least 2 full weeks when possible</li>\"\n",
    "            summary_html += \"<li>\uD83D\uDCC8 Monitor key metrics post-launch to validate test results</li>\"\n",
    "            summary_html += \"<li>\uD83D\uDD0D Use segment analysis to find opportunities for personalization</li>\"\n",
    "            summary_html += \"<li>\uD83D\uDCDD Document your learnings - even 'failed' tests teach you about your users</li>\"\n",
    "            summary_html += \"</ul>\"\n",
    "            \n",
    "            summary_html += \"</div>\"\n",
    "            display(HTML(summary_html))\n",
    "\n",
    "# Attach event handler\n",
    "calculate_button.on_click(on_calculate_click)\n",
    "\n",
    "# Display output area\n",
    "display(HTML(\"<hr>\"))\n",
    "display(output)\n",
    "\n",
    "# Add footer with helpful resources\n",
    "display(HTML(\"\"\"\n",
    "<br><hr>\n",
    "<div style='background-color: #f8f9fa; padding: 20px; border-radius: 10px; margin-top: 20px;'>\n",
    "    <h3>\uD83D\uDCDA Need More Help Understanding Statistics?</h3>\n",
    "    <p><strong>Key Terms Glossary:</strong></p>\n",
    "    <ul style='font-size: 13px;'>\n",
    "        <li><strong>Conversion Rate:</strong> The percentage of users who completed your desired action (e.g., 12% = 12 out of 100 users converted)</li>\n",
    "        <li><strong>Statistical Significance:</strong> When results are unlikely to be due to random chance (typically p-value < 0.05)</li>\n",
    "        <li><strong>P-Value:</strong> Probability that your results happened by pure luck. Lower is better! Under 0.05 is usually considered \"significant\"</li>\n",
    "        <li><strong>Confidence Interval:</strong> A range where we're X% confident the true effect lies. If it doesn't include zero, we have a clear winner</li>\n",
    "        <li><strong>Lift:</strong> The improvement (or decline) from Control to Treatment, expressed as a percentage or percentage points</li>\n",
    "        <li><strong>Sample Size:</strong> The number of users in your test. Bigger samples = more reliable results</li>\n",
    "        <li><strong>Randomization:</strong> The process of fairly assigning users to Control vs. Treatment groups</li>\n",
    "        <li><strong>Type I Error:</strong> Falsely concluding there's an effect when there isn't one (false positive)</li>\n",
    "        <li><strong>Type II Error:</strong> Failing to detect an effect that's really there (false negative)</li>\n",
    "        <li><strong>Statistical Power:</strong> The probability of detecting an effect if one truly exists (higher is better, 80%+ is good)</li>\n",
    "    </ul>\n",
    "    \n",
    "    <p style='margin-top: 20px;'><strong>\uD83D\uDCA1 Pro Tips:</strong></p>\n",
    "    <ul style='font-size: 13px;'>\n",
    "        <li>When in doubt, run longer! More data = more confidence</li>\n",
    "        <li>Don't \"peek\" at results too early and stop the test based on preliminary data</li>\n",
    "        <li>One test doesn't prove everything - successful companies run many tests</li>\n",
    "        <li>Sometimes the best insight is learning what DOESN'T work</li>\n",
    "        <li>Always consider qualitative feedback alongside quantitative results</li>\n",
    "    </ul>\n",
    "    \n",
    "    <p style='margin-top: 20px; color: #666; font-size: 12px;'>\n",
    "        <em>This calculator uses standard frequentist statistical methods (two-proportion z-test) with proper corrections \n",
    "        for multiple testing when analyzing segments.</em>\n",
    "    </p>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AB_Test_UI_w_Charts_and_Inputs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}